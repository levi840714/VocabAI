from aiogram import Router, F
from aiogram.types import Message, CallbackQuery
from aiogram.utils.keyboard import InlineKeyboardBuilder

import re

from bot.services.ai_service import AIService
from bot.database.sqlite_db import add_word
from bot.handlers.common import MAIN_MENU_BUTTON_TEXTS
import logging

router = Router()

def format_word_explanation(structured_data: dict, is_deep_learning: bool = False) -> str:
    """Formats structured word data for display in Telegram."""
    try:
        if is_deep_learning:
            return format_deep_learning_explanation(structured_data)
        
        word = structured_data.get('word', 'Unknown')
        pronunciations = structured_data.get('pronunciations', [])
        definitions = structured_data.get('definitions', [])
        examples = structured_data.get('examples', [])
        synonyms = structured_data.get('synonyms', [])
        antonyms = structured_data.get('antonyms', [])
        memory_tips = structured_data.get('memory_tips', '')
        
        formatted = ""
        
        # Pronunciations
        if pronunciations:
            formatted += f"ğŸ”Š <b>ç™¼éŸ³:</b> {', '.join(pronunciations)}\n\n"
        
        # Definitions
        if definitions:
            formatted += "ğŸ“– <b>å®šç¾©:</b>\n"
            for i, def_group in enumerate(definitions, 1):
                part_of_speech = def_group.get('part_of_speech', '').title()
                meanings = def_group.get('meanings', [])
                
                if part_of_speech:
                    formatted += f"<i>{part_of_speech}</i>\n"
                
                for meaning in meanings:
                    definition = meaning.get('definition', '')
                    context = meaning.get('context', '')
                    formatted += f"â€¢ {definition}"
                    if context:
                        formatted += f" ({context})"
                    formatted += "\n"
                formatted += "\n"
        
        # Examples
        if examples:
            formatted += "ğŸ’¡ <b>ä¾‹å¥:</b>\n"
            for example in examples[:3]:  # Limit to 3 examples
                formatted += f"â€¢ {example}\n"
            formatted += "\n"
        
        # Synonyms and Antonyms
        if synonyms:
            formatted += f"ğŸ”„ <b>åŒç¾©è©:</b> {', '.join(synonyms)}\n"
        if antonyms:
            formatted += f"âš¡ <b>åç¾©è©:</b> {', '.join(antonyms)}\n"
        
        # Memory tips
        if memory_tips and memory_tips != "None":
            formatted += f"\nğŸ§  <b>è¨˜æ†¶å°æŠ€å·§:</b> {memory_tips}"
        
        return formatted.strip()
    except Exception as e:
        logging.error(f"Error formatting word explanation: {e}")
        # Fallback to basic word info if formatting fails
        word = structured_data.get('word', 'Unknown')
        return f"âš ï¸ æ ¼å¼åŒ–å¤±æ•—ï¼Œä½†æ‰¾åˆ°å–®å­—: <b>{word}</b>\nè«‹ç¨å¾Œå†è©¦ã€‚"

def format_deep_learning_explanation(structured_data: dict) -> str:
    """Formats deep learning structured word data for display in Telegram."""
    try:
        word = structured_data.get('word', 'Unknown')
        pronunciations = structured_data.get('pronunciations', [])
        etymology = structured_data.get('etymology', {})
        definitions = structured_data.get('definitions', [])
        collocations = structured_data.get('collocations', {})
        examples = structured_data.get('examples', [])
        synonyms = structured_data.get('synonyms', [])
        antonyms = structured_data.get('antonyms', [])
        memory_strategies = structured_data.get('memory_strategies', {})
        cultural_notes = structured_data.get('cultural_notes', '')
        difficulty_level = structured_data.get('difficulty_level', '')
        frequency = structured_data.get('frequency', '')
        
        formatted = ""
        
        # Header with level and frequency
        if difficulty_level or frequency:
            formatted += f"ğŸ“Š <b>ç´šåˆ¥:</b> {difficulty_level} | <b>é »ç‡:</b> {frequency}\n\n"
        
        # Pronunciations
        if pronunciations:
            formatted += f"ğŸ”Š <b>ç™¼éŸ³:</b> {', '.join(pronunciations)}\n\n"
        
        # Etymology
        if etymology:
            formatted += "ğŸ›ï¸ <b>è©æºåˆ†æ:</b>\n"
            if etymology.get('origin'):
                formatted += f"â€¢ ä¾†æº: {etymology['origin']}\n"
            if etymology.get('root_analysis'):
                formatted += f"â€¢ å­—æ ¹: {etymology['root_analysis']}\n"
            if etymology.get('related_words'):
                formatted += f"â€¢ ç›¸é—œè©: {', '.join(etymology['related_words'][:5])}\n"
            formatted += "\n"
        
        # Definitions with enhanced info
        if definitions:
            formatted += "ğŸ“– <b>è©³ç´°å®šç¾©:</b>\n"
            for def_group in definitions:
                part_of_speech = def_group.get('part_of_speech', '').title()
                meanings = def_group.get('meanings', [])
                
                if part_of_speech:
                    formatted += f"<i>{part_of_speech}</i>\n"
                
                for meaning in meanings:
                    definition = meaning.get('definition', '')
                    context = meaning.get('context', '')
                    formality = meaning.get('formality', '')
                    usage_notes = meaning.get('usage_notes', '')
                    
                    formatted += f"â€¢ {definition}"
                    if context:
                        formatted += f" ({context})"
                    if formality:
                        formatted += f" [{formality}]"
                    formatted += "\n"
                    if usage_notes:
                        formatted += f"  âš ï¸ {usage_notes}\n"
                formatted += "\n"
        
        # Collocations
        if collocations:
            formatted += "ğŸ”— <b>å¸¸ç”¨æ­é…:</b>\n"
            if collocations.get('common_phrases'):
                formatted += f"â€¢ ç‰‡èª: {', '.join(collocations['common_phrases'][:3])}\n"
            if collocations.get('verb_combinations'):
                formatted += f"â€¢ å‹•è©: {', '.join(collocations['verb_combinations'][:3])}\n"
            formatted += "\n"
        
        # Enhanced Examples
        if examples:
            formatted += "ğŸ’¡ <b>æƒ…å¢ƒä¾‹å¥:</b>\n"
            for example in examples[:2]:  # Limit to 2 examples for deep learning
                if isinstance(example, dict):
                    sentence = example.get('sentence', '')
                    translation = example.get('translation', '')
                    context = example.get('context', '')
                    formatted += f"â€¢ {sentence}\n"
                    if translation:
                        formatted += f"  ğŸ“ {translation}\n"
                    if context:
                        formatted += f"  ğŸ¯ {context}\n"
                else:
                    formatted += f"â€¢ {example}\n"
            formatted += "\n"
        
        # Enhanced Synonyms
        if synonyms:
            formatted += "ğŸ”„ <b>åŒç¾©è©æ¯”è¼ƒ:</b>\n"
            for synonym in synonyms[:3]:
                if isinstance(synonym, dict):
                    word_syn = synonym.get('word', '')
                    difference = synonym.get('difference', '')
                    formatted += f"â€¢ {word_syn}: {difference}\n"
                else:
                    formatted += f"â€¢ {synonym}\n"
            formatted += "\n"
        
        # Memory Strategies
        if memory_strategies:
            formatted += "ğŸ§  <b>è¨˜æ†¶ç­–ç•¥:</b>\n"
            if memory_strategies.get('visual'):
                formatted += f"ğŸ‘ï¸ è¦–è¦º: {memory_strategies['visual']}\n"
            if memory_strategies.get('association'):
                formatted += f"ğŸ”— è¯æƒ³: {memory_strategies['association']}\n"
            formatted += "\n"
        
        # Cultural Notes
        if cultural_notes:
            formatted += f"ğŸŒ <b>æ–‡åŒ–èƒŒæ™¯:</b>\n{cultural_notes}\n\n"
        
        return formatted.strip()
    except Exception as e:
        logging.error(f"Error formatting deep learning explanation: {e}")
        # Fallback to basic word info if formatting fails
        word = structured_data.get('word', 'Unknown')
        return f"âš ï¸ æ·±åº¦å­¸ç¿’æ ¼å¼åŒ–å¤±æ•—ï¼Œä½†æ‰¾åˆ°å–®å­—: <b>{word}</b>\nè«‹ç¨å¾Œå†è©¦ã€‚"

def extract_chinese_definitions(structured_data: dict) -> str:
    """Extracts Chinese definitions from structured data for database storage."""
    try:
        definitions = structured_data.get('definitions', [])
        chinese_definitions = []
        
        for def_group in definitions:
            meanings = def_group.get('meanings', [])
            for meaning in meanings:
                definition = meaning.get('definition', '')
                if definition and definition.strip():
                    # Only take Chinese characters, skip English definitions
                    if any('\u4e00' <= char <= '\u9fff' for char in definition):
                        chinese_definitions.append(definition.strip())
        
        if chinese_definitions:
            return '; '.join(chinese_definitions[:3])  # Limit to first 3 definitions
        else:
            # If no Chinese found in definitions, try to get the first meaningful definition
            for def_group in definitions:
                meanings = def_group.get('meanings', [])
                for meaning in meanings:
                    definition = meaning.get('definition', '')
                    if definition and definition.strip():
                        return definition.strip()
            
            return "æœªæ‰¾åˆ°ä¸­æ–‡å®šç¾©"
    except Exception as e:
        logging.error(f"Error extracting Chinese definitions: {e}")
        return "è§£æéŒ¯èª¤"

@router.message(F.text & ~F.text.startswith('/'))
async def handle_word_message(message: Message, ai_service: AIService, config: dict):
    """Handles regular text messages as potential words to be added."""
    word = message.text.strip()
    raw_explanation = await ai_service.get_simple_explanation(word)
    
    # Try to parse JSON response
    structured_data = ai_service.parse_structured_response(raw_explanation)
    
    # Format the response for display
    formatted_explanation = format_word_explanation(structured_data)

    builder = InlineKeyboardBuilder()
    builder.button(text="Add to Vocabulary", callback_data=f"add_word:{word}")

    await message.answer(
        f"<b>{word}</b>\n\n{formatted_explanation}",
        reply_markup=builder.as_markup(),
        parse_mode='HTML'
    )

@router.callback_query(F.data.startswith("add_word:"))
async def process_add_word_callback(callback_query: CallbackQuery, ai_service: AIService, config: dict):
    """Handles the 'Add to Vocabulary' button callback."""
    _, word = callback_query.data.split(":", 1)
    user_id = callback_query.from_user.id
    db_path = config['database']['db_path']

    raw_explanation = await ai_service.get_simple_explanation(word)
    structured_data = ai_service.parse_structured_response(raw_explanation)
    
    # Extract Chinese definitions for database storage
    chinese_meaning = extract_chinese_definitions(structured_data)
    
    # Format for display
    formatted_explanation = format_word_explanation(structured_data)

    if await add_word(db_path, user_id, word, raw_explanation, chinese_meaning):
        await callback_query.answer("å–®å­—å·²æˆåŠŸåŠ å…¥è©å½™åº«ï¼")
        await callback_query.message.edit_text(
            f"<b>{word}</b>\n\n{formatted_explanation}\n\n<i>âœ… å·²åŠ å…¥æ‚¨çš„è©å½™åº«ã€‚</i>", 
            parse_mode='HTML'
        )
        return
    else:
        await callback_query.answer("æ­¤å–®å­—å·²åœ¨æ‚¨çš„è©å½™åº«ä¸­ã€‚", show_alert=True)
